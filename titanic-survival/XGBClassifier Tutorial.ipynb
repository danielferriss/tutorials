{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Likelihood with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial I will explain how to estimate if a passenger on the Titanic will survive using a machine learning algorithm, XGBClassifier. The data for this tutorial is sourced from kaggle.com. Tutorial adapted from [here](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy/notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a library that provides easy-to-use data structeres and data analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn is a machine learning library. Model selection helps choose what data model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing transforms data so that it is easier to read for a computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the machine learning algorithm we will use. We are using classification instead of regression because we are predicting group membership (alive or dead). Regression predicts a quantity i.e. a house price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('train.csv')\n",
    "raw_test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables 'raw_train' and 'raw_test' are both DataFrames. A DataFrame is a variable type from the pandas package. It is essentially a spreadsheet that plays nicely with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the meaning of the column labels.<br>\n",
    "'PassengerId': ID number of the passenger<br>\n",
    "'Survived': Boolean. 0 is False, 1 True<br>\n",
    "'Pclass': Ticket class. 1 is highest<br>\n",
    "'Name': Name<br>\n",
    "'Sex': Sex<br>\n",
    "'Age': Age in years<br>\n",
    "'SibSp': Number of siblings/spouses aboard the Titanic<br>\n",
    "'Parch': Number of parents/children aboard the Titanic<br>\n",
    "'Ticket': Ticket number<br>\n",
    "'fare': Passenger fare in dollars<br>\n",
    "'Cabin': Cabin number<br>\n",
    "'Embarked': Port of embarkment. C = Cherbourg, Q = Queenstown, S = Southampton<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.copy(deep=True)\n",
    "test  = raw_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'.copy()' is a function from pandas. 'deep=True' means that we are copying the data. Without this, python would only copy the reference to the DataFrame. This means that if we changed anything in 'train', it would change on 'raw_train' and vice versa because they are both pointing to the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [train, test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line makes it so we can easily change both train and test in one line of code rather than a line for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you start working with a set of data you must clean it. This means you remove any unnecessary data. You also must replace data that is missing with a reasonable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our training data we have 891 entries. We have a majority of the data for each column, save 'Cabin'. This means that we will be able to make an educated guess and fill in the missing data for most points. We will have to drop the 'Cabin' column because there is not enough data to make educated guesses to fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have most of the data, save 'Cabin'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in clean_data:\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fill in our missing data. '.fillna()' is a method in pandas that fills empty cells in a DataFrame. The first argument is what value to fill cell with. We are using either 'median()' or 'mode()'. These, again, are pandas methods. They get the median or mode, respectively, from whichever column they are called on. The second argument, 'inplace', means that we are performing the operations and saving them into the DataFrame that we are calling 'fillna()' on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will drop the unnecessary data. As stated earlier, there are too few data points for 'Cabin' for it to be of any use, so we will drop it. 'PassengerId' and 'Ticket' do not have any effect on the likelihood of survival, as they are essentially randomly assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['PassengerId', 'Cabin', 'Ticket']\n",
    "train.drop(drop_columns, axis=1, inplace=True)\n",
    "test.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both 'train' and 'test' should have no null objects and be missing the columns we dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "Pclass      418 non-null int64\n",
      "Name        418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         418 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        418 non-null float64\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 26.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are times when your data set may contain features that have little usage in their original state, but still contain useful data. For example, as it stands now, the 'Name' is of little use. However, one could guess that the title of each individual (Mr., Miss., etc.) could have some sort of correlation with survival rate. Adding this derivative data as an extra feature gives the algorithm more data to work off of, and can increase its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in clean_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a lot in a few lines, so I will go line by line.<br>\n",
    "Line 1: The for loop is going through 'clean_data' so we apply these changes to both 'train' and 'test'.\n",
    "'dataset['FamilySize']' creates a new column that will contain the size of the family, so siblings+parents and children.<br><br>\n",
    "Line 2: 'dataset['Title']' creates the 'Title' column. We need to glean the title from the name column. Let's look at 'Braund, Mr. Owen Harris' as an example. The first split, at \", \" will return ['Braund', 'Mr. Owen Harris']. It is returned as a DataFrame because we use 'expand=True'. With '[1]' we access the second element of the DataFrame, then split again at \".\", returning ['Mr', ' Owen Harris']. Finally, we access 'Mr' with '[0]' and add it into the 'Title' column.<br><br>\n",
    "Line 3: We are creating bins for the 'Fare' column data. This means that we are generalizing the data into groups. We do this because it is unlikely that a fare of \\$5.55 will effect the outcome much differently than one of \\$5.60. To create these bins we are using 'qcut()', a pandas method. 'qcut()' will seperate the data given in the first argument into the amount of bins given in the second argument. Each bin will have exactly the same amount of records.<br><br>\n",
    "Line 4: Similar to Line 3 we are splitting the 'Age' column into bins. This time, though, we are using 'cut()' (again, a pandas method). This will choose the bins to be evenly spaced based off of the values. This means that there will not be a congruent number of records in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Mlle              2\n",
       "Col               2\n",
       "Major             2\n",
       "Sir               1\n",
       "Lady              1\n",
       "Ms                1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Jonkheer          1\n",
       "Mme               1\n",
       "Capt              1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the titles we got, along with their counts. We are going to replace any titles with a count of under 10 with 'Misc' as they are statistically insignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              False\n",
       "Miss            False\n",
       "Mrs             False\n",
       "Master          False\n",
       "Dr               True\n",
       "Rev              True\n",
       "Mlle             True\n",
       "Col              True\n",
       "Major            True\n",
       "Sir              True\n",
       "Lady             True\n",
       "Ms               True\n",
       "Don              True\n",
       "the Countess     True\n",
       "Jonkheer         True\n",
       "Mme              True\n",
       "Capt             True\n",
       "Name: Title, dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Title'].value_counts() < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_counts = train['Title'].value_counts() < 10\n",
    "train['Title'] = train['Title'].apply(lambda x: 'Misc' if title_counts.loc[x] == True else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      182\n",
       "Mrs       125\n",
       "Master     40\n",
       "Misc       27\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our data into something that is a bit more readable for the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initializes scikit-learn LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in clean_data:    \n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all datasets are easily readable for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>Sex_Code</th>\n",
       "      <th>Embarked_Code</th>\n",
       "      <th>Title_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "      <th>FareBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Embarked  FamilySize Title  \\\n",
       "0    male  22.0      1      0   7.2500        S           2    Mr   \n",
       "1  female  38.0      1      0  71.2833        C           2   Mrs   \n",
       "2  female  26.0      0      0   7.9250        S           1  Miss   \n",
       "3  female  35.0      1      0  53.1000        S           2   Mrs   \n",
       "4    male  35.0      0      0   8.0500        S           1    Mr   \n",
       "\n",
       "           FareBin        AgeBin  Sex_Code  Embarked_Code  Title_Code  \\\n",
       "0   (-0.001, 7.91]  (16.0, 32.0]         1              2           3   \n",
       "1  (31.0, 512.329]  (32.0, 48.0]         0              0           4   \n",
       "2   (7.91, 14.454]  (16.0, 32.0]         0              2           2   \n",
       "3  (31.0, 512.329]  (32.0, 48.0]         0              2           4   \n",
       "4   (7.91, 14.454]  (32.0, 48.0]         1              2           3   \n",
       "\n",
       "   AgeBin_Code  FareBin_Code  \n",
       "0            1             0  \n",
       "1            2             3  \n",
       "2            1             1  \n",
       "3            2             3  \n",
       "4            2             1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survey Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data all cleaned up and converted we can finally see how each feature correlates with survival rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = ['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target is what the output of the algorithm should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all of the features our algorithm will use when calculating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the correlation between our features and our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Correlation by: Sex\n",
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Pclass\n",
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Embarked\n",
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Title\n",
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Misc  0.444444\n",
      "2    Miss  0.697802\n",
      "3      Mr  0.156673\n",
      "4     Mrs  0.792000\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: SibSp\n",
      "   SibSp  Survived\n",
      "0      0  0.345395\n",
      "1      1  0.535885\n",
      "2      2  0.464286\n",
      "3      3  0.250000\n",
      "4      4  0.166667\n",
      "5      5  0.000000\n",
      "6      8  0.000000\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: Parch\n",
      "   Parch  Survived\n",
      "0      0  0.343658\n",
      "1      1  0.550847\n",
      "2      2  0.500000\n",
      "3      3  0.600000\n",
      "4      4  0.000000\n",
      "5      5  0.200000\n",
      "6      6  0.000000\n",
      "---------- \n",
      "\n",
      "Survival Correlation by: FamilySize\n",
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n",
      "---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in train_x:\n",
    "    if train[x].dtype != 'float64' :\n",
    "        print('Survival Correlation by:', x)\n",
    "        print(train[[x, Target[0]]].groupby(x, as_index=False).mean())\n",
    "        print('-'*10, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of that out of the way we can apply our machine learning algorithm. Like I said earlier, we will use 'XGBClassifier()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a test and train set using sklearn 'ShuffleSplit()'. 'n_splits' is how many times we run the model. We test it with 30% of the data and train it with 60% of the data. We set a random state so that the output is the same every time, so it is replicatable on others' machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_validate(alg, train[train_x_bin], pd.Series.ravel(train[Target]), cv  = split, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally implement the ML algorithm using 'cross_validate()'. The first argument is the MLA, second is the dats, third is target (we used pandas 'ravel()' to make it into a 1d array becuase it must be that shape), fourth is our data split, fifth is a boolean telling it to return the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85636704119850171"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['train_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83955224,  0.80223881,  0.83208955,  0.81343284,  0.83208955,\n",
       "        0.82835821,  0.81343284,  0.82462687,  0.83955224,  0.86940299])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
